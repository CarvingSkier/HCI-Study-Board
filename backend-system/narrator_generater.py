"""
narrator_generater.py â€” Simple JSON Narrator Generator (No Smart Assistant summary)

Reads:
    prompts/Persona_*_Activity_*.txt   (each file is a JSON with persona_desc, context_scenario, assistant_feedback, etc.)

Writes:
    Narrator/Persona_*_Activity_*_Description.txt

Each output file is a JSON with the structure:
{
  "User Name": "<string>",
  "Activity Description": "<string>",
  "Smart Assistant Interaction": "PlaceHolderA"
}

è¡Œä¸ºçº¦å®šï¼š
- é»˜è®¤æƒ…å†µä¸‹ï¼šåªä¸ºâ€œè¿˜æ²¡æœ‰ _Description.txt çš„ Promptâ€ç”Ÿæˆæ–‡ä»¶ï¼›
- å·²ç»å­˜åœ¨çš„ *_Description.txt ä¼šè¢«è·³è¿‡ï¼ˆé™¤éæ˜¾å¼åŠ  --overwriteï¼‰ã€‚
"""

import os
import json
import argparse
from pathlib import Path
from typing import Any, Dict, Optional

from dotenv import load_dotenv
from openai import OpenAI


# -----------------------------
# Basic FS helpers
# -----------------------------
def ensure_dir(p: Path) -> None:
    p.mkdir(parents=True, exist_ok=True)


def read_text(p: Path) -> str:
    return p.read_text(encoding="utf-8")


def write_text(p: Path, text: str) -> None:
    p.write_text(text, encoding="utf-8")


def load_json(p: Path) -> Dict[str, Any]:
    try:
        return json.loads(read_text(p))
    except Exception as e:
        raise RuntimeError(f"Failed to parse JSON in {p}: {e}")


# -----------------------------
# OpenAI helpers
# -----------------------------
def extract_text(resp) -> str:
    """
    å°è¯•ä» OpenAI SDK è¿”å›å¯¹è±¡ä¸­æå–çº¯æ–‡æœ¬ã€‚
    å…¼å®¹ Responses API å’Œ Chat Completionsã€‚
    """
    # 1) Responses API: output_text
    try:
        if hasattr(resp, "output_text") and resp.output_text:
            return resp.output_text.strip()
    except Exception:
        pass

    # 2) Responses API: éå† output -> content -> text
    try:
        parts = []
        for item in getattr(resp, "output", []) or []:
            for c in getattr(item, "content", []) or []:
                t = getattr(c, "text", None)
                if t:
                    parts.append(t)
        text = "\n".join(parts).strip()
        if text:
            return text
    except Exception:
        pass

    # 3) Chat Completions
    try:
        choices = getattr(resp, "choices", None)
        if choices and len(choices) > 0:
            msg = choices[0].message
            if msg and getattr(msg, "content", ""):
                return msg.content.strip()
    except Exception:
        pass

    snippet = repr(resp)
    if len(snippet) > 800:
        snippet = snippet[:800] + "... <truncated>"
    raise RuntimeError(
        "Unable to extract text from response; unexpected SDK structure or empty result.\n"
        f"Raw resp: {snippet}"
    )


def call_llm(client: OpenAI, model: str, sys_prompt: Optional[str], user_prompt: str, temperature: float) -> str:
    """
    ä¼˜å…ˆä½¿ç”¨ Responses APIï¼Œå¤±è´¥åˆ™å›é€€åˆ° Chat Completionsã€‚
    è¿”å›çº¯æ–‡æœ¬ã€‚
    """
    # Try Responses API
    try:
        if sys_prompt:
            resp = client.responses.create(
                model=model,
                input=[
                    {"role": "system", "content": sys_prompt},
                    {"role": "user", "content": user_prompt},
                ],
                temperature=temperature,
            )
        else:
            resp = client.responses.create(
                model=model,
                input=user_prompt,
                temperature=temperature,
            )
        try:
            return extract_text(resp)
        except Exception as inner_e:
            print(f"âš ï¸ Responses API returned unusable payload, falling back to chat.completions: {inner_e}")
    except Exception as e:
        print(f"âš ï¸ Responses API call failed, falling back to chat.completions: {e}")

    # Fallback: Chat Completions
    messages = [{"role": "user", "content": user_prompt}]
    if sys_prompt:
        messages.insert(0, {"role": "system", "content": sys_prompt})

    resp = client.chat.completions.create(
        model=model,
        messages=messages,
        temperature=temperature,
    )
    return extract_text(resp)


def parse_json_from_model_output(text: str) -> Dict[str, Any]:
    """
    æ¨¡å‹å¿…é¡»è¾“å‡º JSONï¼Œä½†ä¸ºäº†é˜²å¾¡ï¼š
    - å»æ‰ ```json ... ``` æˆ– ``` åŒ…è£¹
    - å†åš json.loads
    """
    s = text.strip()

    # å»æ‰ä»£ç å—
    if s.startswith("```"):
        # å¯èƒ½æ˜¯ ```json ... ```
        lines = s.splitlines()
        if len(lines) >= 2 and lines[0].startswith("```"):
            # æ‰¾åˆ°æœ€åä¸€ä¸ª ``` çš„è¡Œå·
            end_idx = None
            for i in range(len(lines) - 1, -1, -1):
                if lines[i].strip().startswith("```"):
                    end_idx = i
                    break
            if end_idx is not None and end_idx > 0:
                s = "\n".join(lines[1:end_idx]).strip()

    try:
        return json.loads(s)
    except Exception as e:
        raise RuntimeError(f"Failed to parse model output as JSON.\nOutput was:\n{s}\nError: {e}")


# -----------------------------
# Prompt builder
# -----------------------------
def build_user_prompt_for_narrator(full_data: Dict[str, Any]) -> str:
    """
    æ„é€  user promptï¼š
    - è¾“å…¥ï¼šæ•´ä¸ª JSONï¼ˆåŒ…å« persona_desc, context_scenario, assistant_feedback ç­‰ï¼‰
    - è¾“å‡ºï¼šåªéœ€è¦ä¸¤ä¸ªå­—æ®µï¼š
        "User Name"
        "Activity Description"
    ä¹‹å Python å†è¡¥ä¸Š "Smart Assistant Interaction": "PlaceHolderA"
    """
    full_json_block = json.dumps(full_data, ensure_ascii=False, indent=2)

    return f"""You are given a full JSON object describing a persona and a specific scenario.

[FULL_JSON]
{full_json_block}

Your task is to produce a VERY COMPACT JSON summary with EXACTLY TWO fields:

1) "User Name"
   - Infer the preferred name or nickname of the person from the persona description.
   - Look for how they are referred to (e.g., "Wes" instead of "Wilfredo").
   - Use 1â€“2 words only.
   - Do not add any extra explanation.

2) "Activity Description"
   - Write 1â€“3 sentences in English.
   - Summarize what the person is doing in this scenario, based on the context_scenario
     (activity, expanded_activity, reasoning, time, and setting), and overall context.
   - Focus on the concrete real-world action and situation.

IMPORTANT:
- Ignore any requirement to summarize the smart assistant.
- Do NOT include anything about how the assistant behaves.

RESPONSE FORMAT (IMPORTANT):
- Return ONLY a single valid JSON object.
- Do NOT include any comments, explanations, or extra text.
- Keys must be exactly:
  "User Name"
  "Activity Description"

Example shape (values are just placeholders):

{{
  "User Name": "Wes",
  "Activity Description": "Short paragraph about what the user is doing in this scenario."
}}
"""


# -----------------------------
# Main
# -----------------------------
def main():
    parser = argparse.ArgumentParser(
        description="Simple Narrator Generator: output JSON with User Name, Activity Description, Smart Assistant Interaction=PlaceHolderA."
    )
    parser.add_argument("--prompts_dir", default="prompts", help="Directory containing Persona_*_Activity_*.txt JSON files")
    parser.add_argument("--out_dir", default="Narrator", help="Output directory for *_Description.txt JSON files")
    parser.add_argument("--model", default="gpt-4o-mini", help="OpenAI model name")
    parser.add_argument("--temperature", type=float, default=0.3)
    parser.add_argument("--limit", type=int, default=None, help="Optional limit on number of files to process")
    parser.add_argument("--overwrite", action="store_true", help="Overwrite existing output files")
    parser.add_argument("--system", default=None, help="Custom system prompt string or @path/to/file")
    args = parser.parse_args()

    # --- API client ---
    load_dotenv()
    api_key = os.getenv("OPENAI_API_KEY")
    if not api_key:
        raise SystemExit("âŒ Missing OPENAI_API_KEY in .env or environment")
    client = OpenAI(api_key=api_key)

    # --- System prompt ---
    base_system_prompt = (
        "You are a careful summarizer. "
        "You must follow the output JSON schema exactly and never add extra commentary."
    )
    sys_prompt: Optional[str] = base_system_prompt
    if args.system:
        # å…è®¸ä»æ–‡ä»¶è¯»å– system prompt: ä¼ å…¥å½¢å¼ä¸º @path/to/file
        if args.system.startswith("@"):
            sys_prompt = read_text(Path(args.system[1:]))
        else:
            sys_prompt = args.system

    # --- IO paths ---
    prompts_dir = Path(args.prompts_dir)
    out_dir = Path(args.out_dir)
    ensure_dir(out_dir)

    files = sorted(prompts_dir.glob("Persona_*_Activity_*.txt"))
    if args.limit:
        files = files[: args.limit]
    if not files:
        raise SystemExit(f"âŒ No prompt files found under {prompts_dir}/Persona_*_Activity_*.txt")

    processed = 0
    for pf in files:
        try:
            base_stem = pf.stem  # e.g. Persona_1_Activity_35
            out_path = out_dir / f"{base_stem}_Description.txt"  # ä¸æ—§å‘½åä¿æŒä¸€è‡´

            # å…³é”®é€»è¾‘ï¼šé»˜è®¤ä¸è¦†ç›–ï¼Œåªè¡¥ç¼ºå¤±æ–‡ä»¶
            if out_path.exists() and not args.overwrite:
                print(f"â­ï¸  Skip (exists): {out_path.name}")
                continue

            print(f"ğŸ“ Processing {pf.name}")
            data = load_json(pf)

            user_prompt = build_user_prompt_for_narrator(data)

            # è°ƒç”¨ä¸€æ¬¡ LLMï¼Œè¿”å›æ–‡æœ¬ï¼Œå† parse ä¸º JSON
            try:
                raw_output = call_llm(
                    client=client,
                    model=args.model,
                    sys_prompt=sys_prompt,
                    user_prompt=user_prompt,
                    temperature=args.temperature,
                )
            except Exception as e:
                print(f"âš ï¸  LLM call failed for {pf.name}: {e}")
                continue

            try:
                partial_obj = parse_json_from_model_output(raw_output)
            except Exception as e:
                print(f"âš ï¸  Failed to parse JSON for {pf.name}: {e}")
                continue

            # å–å‡ºåç§°ä¸æ´»åŠ¨æè¿°ï¼Œç¨å¾®é˜²å¾¡ä¸€ä¸‹ key å¤§å°å†™æˆ–ä¸‹åˆ’çº¿
            user_name = (
                partial_obj.get("User Name")
                or partial_obj.get("user_name")
                or partial_obj.get("name")
                or ""
            )
            activity_desc = (
                partial_obj.get("Activity Description")
                or partial_obj.get("activity_description")
                or partial_obj.get("Activity")
                or ""
            )

            narrator_obj = {
                "User Name": user_name,
                "Activity Description": activity_desc,
                "Smart Assistant Interaction": "PlaceHolderA",
            }

            json_text = json.dumps(narrator_obj, ensure_ascii=False, indent=2)
            write_text(out_path, json_text)
            print(f"âœ… Saved: {out_path.name}")
            processed += 1

        except Exception as e:
            print(f"âŒ Error: {pf.name}: {e}")

    print(f"\nğŸ‰ Done. Generated {processed} file(s) into: {out_dir}")


if __name__ == "__main__":
    main()
